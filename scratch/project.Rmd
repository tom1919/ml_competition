---
title: "Untitled"
output: html_document
---

File paths, helper functions and packages
```{r}
scripts <- 'C:/Users/tommy/Google Drive/Coursework/1machine_learning/scripts/'
data <- "C:/Users/tommy/Google Drive/Coursework/1machine_learning/data/"
raw <- "C:/Users/tommy/Google Drive/Coursework/1machine_learning/data/raw/"
source(paste0(scripts,'helper_functions.R'))

LoadPackages(c("dplyr", "ggplot2", "caret", "tibble", 'Boruta', 'stringr'))
```

Load data, train and test split
```{r}
load(paste0(raw,"MLProjectData.RData"))
df <-  MLProjectData %>% mutate(id = row_number())
```


```{r}
df_stats <- summarize_df(df)

df_stats %>% arrange(desc(mode_ratio))

# df <-df %>% mutate(rare_98 = ifelse(cat9 == T | 
#                                 cat16 == T |
#                                 cat24 == T |
#                                 cat23 == T |
#                                 cat10 == T |
#                                 cat15 == T |
#                                 cat8 == T |
#                                 cat18 == T |
#                                 cat26 == T, 1, 0 ))

# sum of T/F categorical features
cat_log <- df %>% 
  select(starts_with("cat")) %>% 
  select(-cat1, -cat2) %>%
  mutate(cat_sum = rowSums(.))



df$cat_sum <- cat_log$cat_sum

# # squared terms
# num_vars <- df %>% 
#   select(starts_with("num"))
# 
# sq_num_vars <- num_vars * num_vars
# new_names <- names(sq_num_vars) %>% str_replace_all("num", 'sq_num') 
# names(sq_num_vars) <- new_names
# 
# df <- bind_cols(df, sq_num_vars)
# 
# # interaction terms
# int_terms <- do.call(cbind, combn(colnames(num_vars), 2, FUN= function(x) 
#   list(setNames(data.frame(num_vars[,x[1]]*num_vars[,x[2]]), 
#                 paste(x, collapse="_")) )))
# 
# df <- bind_cols(df, int_terms)
```


```{r}
set.seed(888)
train <- df  %>% sample_frac(.8)
test <- anti_join(df, train, by = "id")
train <- train %>% select(-id)
```

Control model tuning
```{r}
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 1,
                     verboseIter = T)
```

Feature importance using ridge regression
```{r}
set.seed(888)

ridge_grid <- expand.grid(alpha = 0, 
                          lambda = c(seq(0.0001, 1, length =  400),
                                     seq(1,5, length = 100))) %>%
  sample_frac(.2) %>%
  arrange(lambda)

ridge_fit <- train(target ~ ., data = train, tuneGrid = ridge_grid,
                preProcess = c("center", "scale"), metric = "MAE",
                method = "glmnet", trControl = ctrl)

ridge_fit$results %>% arrange(MAE)

ridge_coef <- coef(ridge_fit$finalModel, ridge_fit$bestTune$lambda) %>% 
  as.matrix() %>% as.data.frame() %>% rownames_to_column("feat")

names(ridge_coef) <- c("feat", "coef")

ridge_coef %>% arrange(desc(abs(coef)))
```


Feature importance using boruta algo
```{r}
set.seed(888)
boruta_train <- Boruta(target ~., data = train, doTrace = 2, maxRuns = 20)
final_boruta <- TentativeRoughFix(boruta_train)

boruta_df <- attStats(final_boruta) %>% 
  rownames_to_column("col") %>%
  arrange(desc(meanImp))

# saveRDS(boruta_train, paste0(data, "boruta_train.rds"))
# boruta_train <- readRDS(paste0(data, "boruta_train.rds"))
```

square terms and interactions on important predictors
```{r}
imp_num_vars <- c('num6', 'num5', 'num58', 'num4',
                  'num23', 'num32', "num18", "num58",
                  "num1", "num3", "num5") 

# square terms
num_vars_df <- train %>% select(imp_num_vars)

sq_num_vars <- num_vars_df * num_vars_df
new_names <- names(sq_num_vars) %>% str_replace_all("num", 'sq_num')
names(sq_num_vars) <- new_names

train <- bind_cols(train, sq_num_vars)


# interaction terms
int_terms <- do.call(cbind, combn(colnames(num_vars_df), 2, FUN= function(x)
  list(setNames(data.frame(num_vars_df[,x[1]]*num_vars_df[,x[2]]),
                paste(x, collapse="_")) )))

train <- bind_cols(train, int_terms)

# cat features
train <- train %>% 
  mutate(imp_cat = ifelse(cat13 == T | 
                            cat16 == T |
                            cat6 == T |
                            cat19 == T |
                            cat11 == T, TRUE, FALSE ))
```


Select important features
```{r}
# imp_feat <- boruta_df %>% 
#   filter(decision == "Confirmed") %>% 
#   pull(col)
# 
# train2 <- train[c('target', "cat_sum", "cat1", "cat2", imp_feat)]
```

```{r}
set.seed(888)

enet_grid <- expand.grid(alpha = seq(0,1, length = 15), 
                          lambda = c(seq(0.0001, 1, length =  400),
                                     seq(1,5, length = 100))) %>%
  sample_frac(.015) %>%
  arrange(lambda)

# enet_grid <- expand.grid(alpha = 0.07235714, 
#                           lambda = 3.66666667)

enet_fit <- train(target ~ ., data = train, tuneGrid = enet_grid,
                preProcess = c("center", "scale"), metric = "MAE",
                method = "glmnet", trControl = ctrl)

enet_fit$results %>% arrange(MAE)

enet_fit_coef <- coef(enet_fit$finalModel, enet_fit$bestTune$lambda) %>% 
  as.matrix() %>% as.data.frame() %>% rownames_to_column("feat")

names(enet_fit_coef) <- c("feat", "coef")

enet_fit_coef %>% arrange(desc(abs(coef)))
```

Feature importance using boruta algo 2
```{r}
set.seed(888)
boruta_train2 <- Boruta(target ~., data = train, doTrace = 2, maxRuns = 20)
final_boruta2 <- TentativeRoughFix(boruta_train2)

boruta_df2 <- attStats(final_boruta2) %>% 
  rownames_to_column("col") %>%
  arrange(desc(meanImp))

# saveRDS(boruta_train, paste0(data, "boruta_train.rds"))
# boruta_train <- readRDS(paste0(data, "boruta_train.rds"))
```


```{r}
mod_vars <- boruta_df2 %>%
  slice(1:40) %>% 
  pull(col)

mod_vars <- c("target", "cat_sum",mod_vars, "num1", "num4" )

train2 <- train %>% 
  select(mod_vars) %>% 
  mutate_at("imp_cat", funs(as.numeric(.)))
```






```{r}
set.seed(888)
rf_grid <- expand.grid(mtry = c(2,5,9,12), 
                       min.node.size = c( 12, 16, 25, 40, 60,100),
                       splitrule = c("variance", 'extratrees'))

rf <- train(target ~ ., data = train2, tuneGrid = rf_grid, num.tree = 500, 
            importance = 'permutation', metric = "MAE", method = "ranger", 
            trControl = ctrl)

rf$results %>% arrange(MAE)
```

```{r}
set.seed(888)

xgbl_grid <- expand.grid(eta = 2^seq(-7,-3), 
                         lambda = seq(.01,3, length = 50),
                         alpha = c(0,0.01,0.08,0.1,.5,1),
                         nrounds = c(100,200)
                         ) %>%
  sample_frac(.05)

xgbl <- train(target ~ ., data = train2, tuneGrid = xgbl_grid, metric = "MAE",
              method = "xgbLinea1r", preProcess = c("center", "scale"),
              trControl = ctrl)
```


```{r}
set.seed(888)

knn_grid <- expand.grid(k = seq(40,65,3))
knn <- train(target ~ ., data = train2, tuneGrid = knn_grid ,
             metric = "MAE", method = "knn", trControl = ctrl)
```


```{r}
rf$results %>% arrange(MAE) 

knn$results %>% arrange(MAE) 
```

```{r}
pred <- predict(rf, test)

MAE(pred, test$target)
```

```{r}
mean <- train$target %>% mean()

dim(test)

mean_pred <- rep(mean, 1270)

MAE(mean_pred, test$target)
```

